{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing waveforms\n",
    "directory = ''\n",
    "file_pattern = \"100m_no_occlusion_tx_{:02d}.txt\"\n",
    "num_files = 64\n",
    "\n",
    "# Define segments with their labels\n",
    "# segments = [ #no occlusion 100m\n",
    "#     (0, 5, \"SF7\"), (5, 15, \"SF8\"), \n",
    "#     (19, 65, \"SF10\"), (65, 235, \"SF12\"), \n",
    "#     (237, 244, \"CR2\"), (252, 261, \"CR3\"), \n",
    "#     (261, 268, \"CR4\"), (268, 274, \"Tx1\"), \n",
    "#     (274, 280, \"Tx3\"), (280, 286, \"Tx5\")\n",
    "# ]\n",
    "\n",
    "# segments = [ #for copper 100m\n",
    "#     (0, 0.97, \"SF: 7\"), (0.97, 10.7, \"SF: 8\"), \n",
    "#     (10.7, 60.4, \"SF: 10\"), (60.4, 233, \"SF: 12\"), \n",
    "#     (233, 241.1, \"CR: 2\"), (241.1, 249.5, \"CR: 3\"), \n",
    "#     (249.5, 258.3, \"CR: 4\"), (264.9, 271, \"Tx Power: 3\"), \n",
    "#     (271, 277.4, \"Tx Power: 5\"), (277.4, 283.8, \"Tx Power: 1\"),\n",
    "#     (283.8, 290, 'Tx Power: 14')\n",
    "# ]\n",
    "\n",
    "segments = [ #for 400m\n",
    "    # (0, 0.97, \"SF: 7\"), (0.97, 10.7, \"SF: 8\"), \n",
    "    # (10.7, 60.4, \"SF: 10\"), \n",
    "    (0, 71.7, \"SF: 12\"), \n",
    "    (71.7, 79.3, \"CR: 2\"), (79.3, 86.8, \"CR: 3\"), \n",
    "    (86.8, 89.3, \"CR: 4\")\n",
    "]\n",
    "\n",
    "\n",
    "def read_and_downsample(filepath, downsample_factor=5):\n",
    "    data = pd.read_csv(filepath, sep='\\t', header=0, skiprows=3)\n",
    "    # Ensure we only keep the first two columns\n",
    "    data = data.iloc[::downsample_factor, :2]\n",
    "    # Rename columns to standard names\n",
    "    data.columns = ['Time', 'Voltage']\n",
    "    return data\n",
    "\n",
    "def combine_all_data():\n",
    "    all_data = []\n",
    "    cumulative_time_shift = 0\n",
    "    \n",
    "    for i in range(1, num_files + 1):\n",
    "        file_name = file_pattern.format(i)\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            data = read_and_downsample(file_path)\n",
    "            \n",
    "            if not data.empty:\n",
    "                # Shift time values\n",
    "                data['Time'] += cumulative_time_shift\n",
    "                \n",
    "                all_data.append(data)\n",
    "                \n",
    "                time_step = data['Time'].iloc[1] - data['Time'].iloc[0]\n",
    "                cumulative_time_shift = data['Time'].iloc[-1] + time_step\n",
    "        else:\n",
    "            print(f\"File {file_name} not found.\")\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    return combined_data\n",
    "\n",
    "def plot_segments(data, segments):\n",
    "    for start_time, end_time, label in segments:\n",
    "        mask = (data['Time'] >= start_time) & (data['Time'] <= end_time)\n",
    "        segment_data = data[mask].copy()\n",
    "        \n",
    "        if not segment_data.empty:\n",
    "            print(f\"Plotting segment {label} ({start_time}-{end_time}s)\")\n",
    "            print(f\"Number of points in segment: {len(segment_data)}\")\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=segment_data['Time'],\n",
    "                y=segment_data['Voltage'],\n",
    "                mode='lines',\n",
    "                name=label\n",
    "            ))\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=f'Segment: {label} (Time: {start_time}-{end_time}s)',\n",
    "                xaxis_title='Time (s)',\n",
    "                yaxis_title='Voltage (V)',\n",
    "                showlegend=True\n",
    "            )\n",
    "            \n",
    "            fig.show()\n",
    "        else:\n",
    "            print(f\"No data found for segment {label} ({start_time}-{end_time}s)\")\n",
    "\n",
    "def main():\n",
    "    print(\"Combining all data...\")\n",
    "    combined_data = combine_all_data()\n",
    "    \n",
    "    print(f\"Combined data shape: {combined_data.shape}\")\n",
    "    print(\"Time range:\", combined_data['Time'].min(), \"to\", combined_data['Time'].max())\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = \"combined_waveform_data.csv\"\n",
    "    combined_data.to_csv(output_file, index=False)\n",
    "    print(f\"Combined data saved to {output_file}\")\n",
    "    \n",
    "    # Create individual plots for each segment\n",
    "    print(\"Creating segment plots...\")\n",
    "    plot_segments(combined_data, segments)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "# Directory containing waveforms\n",
    "directory = ''\n",
    "file_pattern = \"100m_no_occlusion_tx_{:02d}.txt\"\n",
    "num_files = 64\n",
    "kernel = 21\n",
    "poles = 7\n",
    "cutoff = 30\n",
    "resistor = 18\n",
    "voltage = 3.3\n",
    "\n",
    "# Define segments\n",
    "segments = [ #for no occlusion 100m\n",
    "    (0, 5, \"SF: 7\"), (5, 15, \"SF: 8\"), \n",
    "    (19, 65, \"SF: 10\"), (65, 236.6, \"SF: 12\"), \n",
    "    (237, 244, \"CR: 2\"), (252.2, 261.3, \"CR: 3\"), \n",
    "    (261.3, 268, \"CR: 4\"), (268, 274, \"Tx Power: 3\"), \n",
    "    (274, 280.2, \"Tx Power: 5\"), (280.2, 286, \"Tx Power: 1\"),\n",
    "    (286.5, 293, 'Tx Power: 14')\n",
    "]\n",
    "\n",
    "# segments = [ #for copper 100m\n",
    "#     (0, 0.97, \"SF: 7\"), (0.97, 10.7, \"SF: 8\"), \n",
    "#     (10.7, 60.4, \"SF: 10\"), (60.4, 233, \"SF: 12\"), \n",
    "#     (233, 241.1, \"CR: 2\"), (241.1, 249.5, \"CR: 3\"), \n",
    "#     (249.5, 258.3, \"CR: 4\"), (264.9, 271, \"Tx Power: 3\"), \n",
    "#     (271, 277.4, \"Tx Power: 5\"), (277.4, 283.8, \"Tx Power: 1\"),\n",
    "#     (283.8, 290, 'Tx Power: 14')\n",
    "# ]\n",
    "\n",
    "# segments = [ #for 400m\n",
    "#     # (0, 0.97, \"SF: 7\"), (0.97, 10.7, \"SF: 8\"), \n",
    "#     # (10.7, 60.4, \"SF: 10\"), \n",
    "#     (0, 71.7, \"SF: 12\"), \n",
    "#     (71.7, 79.3, \"CR: 2\"), (79.3, 86.8, \"CR: 3\"), \n",
    "#     (86.8, 99.3, \"CR: 4\")\n",
    "# ]\n",
    "\n",
    "def read_and_downsample(filepath, downsample_factor=10):\n",
    "    data = pd.read_csv(filepath, sep='\\t', header=0, skiprows=3)\n",
    "    data = data.iloc[::downsample_factor, :2]\n",
    "    # Rename columns\n",
    "    data.columns = ['Time', 'Voltage']\n",
    "    data['Voltage'] = data['Voltage']\n",
    "\n",
    "    #Filter data\n",
    "    filtered_data = data.copy()\n",
    "    sample_rate = 1 / np.mean(np.diff(data['Time']))\n",
    "    sos = scipy.signal.butter(poles, cutoff, 'lowpass', fs=sample_rate, output='sos')\n",
    "    filtered_data['Voltage'] = scipy.signal.sosfiltfilt(sos, filtered_data['Voltage'])\n",
    "    filtered_data['Voltage'] = medfilt(data['Voltage'], kernel)\n",
    "\n",
    "    #Calculate current from voltage given value of shunt resistor\n",
    "    filtered_data['Current'] = filtered_data['Voltage']/resistor\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def combine_all_data():\n",
    "    all_data = []\n",
    "    cumulative_time_shift = 0\n",
    "    \n",
    "    for i in range(1, num_files + 1):\n",
    "        file_name = file_pattern.format(i)\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            data = read_and_downsample(file_path)\n",
    "            \n",
    "            if not data.empty:\n",
    "                data['Time'] = data['Time'] + cumulative_time_shift\n",
    "\n",
    "                all_data.append(data)\n",
    "                \n",
    "                # Update cumulative_time_shift for next file\n",
    "                cumulative_time_shift = data['Time'].max()\n",
    "                \n",
    "                # Add gap between files to prevent overlap\n",
    "                cumulative_time_shift += 0.0001\n",
    "                \n",
    "            else:\n",
    "                print(f\"Empty data in file {file_name}\")\n",
    "        else:\n",
    "            print(f\"File {file_name} not found.\")\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    combined_data = combined_data.sort_values('Time').reset_index(drop=True)\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "def plot_segments(data, segments):\n",
    "    # threshold for current changes \n",
    "    threshold = 0.01\n",
    "\n",
    "    # column for detecting when current changes beyond threshold\n",
    "    data['current_change'] = data['Current'].diff().abs() > threshold\n",
    "\n",
    "    # Cumulative sum to group sections with the same current level\n",
    "    data['current_group'] = data['current_change'].cumsum()\n",
    "\n",
    "    # Calculate duration (in ms) spent at each current level\n",
    "    grouped = data.groupby('current_group').agg(\n",
    "        current=('Current', 'mean'),\n",
    "        start_time=('Time', 'min'),\n",
    "        end_time=('Time', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate the duration in milliseconds for each current level\n",
    "    grouped['duration_ms'] = (grouped['end_time'] - grouped['start_time']) * 1000\n",
    "    # Remove rows where duration is 0\n",
    "    grouped = grouped[grouped['duration_ms'] > 0]\n",
    "    grouped.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    for start_time, end_time, label in segments:\n",
    "        mask = (data['Time'] >= start_time) & (data['Time'] <= end_time)\n",
    "        segment_data = data[mask].copy()\n",
    "\n",
    "        segment_grouped = grouped[(grouped['start_time'] >= start_time) & (grouped['end_time'] <= end_time)].copy()\n",
    "        segment_grouped['Power'] = segment_grouped['current'] * voltage #current * voltage supply\n",
    "        segment_grouped['Energy'] = segment_grouped['Power'] * segment_grouped['duration_ms']/1000 #in Watt/seconds or Joules\n",
    "        \n",
    "        if not segment_grouped.empty:\n",
    "            print(segment_grouped[['current', 'duration_ms', 'Power', 'Energy']].to_csv(index=True))\n",
    "            total_energy = segment_grouped['Energy'].sum()\n",
    "            total_duration = segment_grouped['duration_ms'].sum()\n",
    "\n",
    "            print(f\"Total duration: {total_duration:.5f} ms\\n\")\n",
    "            print(f\"Total energy: {total_energy:.5f} J (or Ws)\\n\")\n",
    "        else:\n",
    "            \"No current data\"\n",
    "\n",
    "        if not segment_data.empty:  \n",
    "\n",
    "            try:\n",
    "                fig = go.Figure()\n",
    "                \n",
    "                trace = go.Scatter(\n",
    "                    x=segment_data['Time'].values,\n",
    "                    y=segment_data['Current'].values,\n",
    "                    mode='lines',\n",
    "                    name=label\n",
    "                )\n",
    "                \n",
    "                fig.add_trace(trace)\n",
    "                \n",
    "                fig.update_layout(\n",
    "                    title=f'Test: {label}',\n",
    "                    xaxis_title='Time (s)',\n",
    "                    yaxis_title='Current (A)',\n",
    "                    showlegend=True\n",
    "                )\n",
    "                \n",
    "                fig.show()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error creating/showing plot for segment {label}: {str(e)}\")\n",
    "                print(\"Data types:\")\n",
    "                print(segment_data.dtypes)\n",
    "                print(\"\\nAny NaN values?\")\n",
    "                print(segment_data.isna().sum())\n",
    "                \n",
    "        else:\n",
    "            print(f\"No data found for segment {label} ({start_time}-{end_time}s)\")\n",
    "\n",
    "def plot_segments_html(data, segments):\n",
    "    for start_time, end_time, label in segments:\n",
    "        print(f\"\\nProcessing segment {label} ({start_time}-{end_time}s)\")\n",
    "        \n",
    "        mask = (data['Time'] >= start_time) & (data['Time'] <= end_time)\n",
    "        segment_data = data[mask].copy()\n",
    "        \n",
    "        if not segment_data.empty:  \n",
    "            fig = go.Figure()\n",
    "            \n",
    "            trace = go.Scatter(\n",
    "                x=segment_data['Time'].values,\n",
    "                y=segment_data['Current'].values,\n",
    "                mode='lines',\n",
    "                name=label\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(trace)\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=f'Test: {label}',\n",
    "                xaxis_title='Time (s)',\n",
    "                yaxis_title='Current (A)',\n",
    "                showlegend=True,\n",
    "                width=1200,\n",
    "                height=400,\n",
    "                margin=dict(l=50, r=50, t=50, b=50)\n",
    "            )\n",
    "            \n",
    "            output_file = f\"segment_{label.lower()}.html\"\n",
    "            fig.write_html(output_file)\n",
    "\n",
    "def main():\n",
    "    # Combine all data\n",
    "    print(\"Combining all data...\")\n",
    "    combined_data = combine_all_data()\n",
    "    \n",
    "    print(\"\\nCombined data summary:\")\n",
    "    print(f\"Total points: {len(combined_data)}\")\n",
    "    print(f\"Time range: {combined_data['Time'].min():.6f} to {combined_data['Time'].max():.6f}\")\n",
    "    print(f\"Number of unique time points: {combined_data['Time'].nunique()}\")\n",
    "    \n",
    "    output_file = \"combined_waveform_data.csv\"\n",
    "    combined_data.to_csv(output_file, index=False)\n",
    "    print(f\"\\nCombined data saved to {output_file}\")\n",
    "    \n",
    "    # Create individual plots for each segment\n",
    "    print(\"\\nCreating segment plots...\")\n",
    "    plot_segments(combined_data, segments)\n",
    "    plot_segments_html(combined_data, segments)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Estimating for incomplete plots\n",
    "# SF7, CR1, Tx10\n",
    "max_I = 0.077 # max current when Tx for copper occlusion\n",
    "min_I = 0.009 # min current for copper occlusion\n",
    "# Full SF7 time durations estimation\n",
    "durations = np.array([365.49999, 365.49999, 365.49999, 365.49999, 398.99998999999997,\n",
    "98.99998999999985, 365.4999899999998, 398.9999899999996,\n",
    "365.49999, 398.9999899999996, 365.49999,\n",
    "398.9999900000001, 364.99999000000023, 112.4999999999998,\n",
    "457.4999899999996, 29.99999999999936])\n",
    "\n",
    "max_power = max_I * 3.3\n",
    "min_power = min_I * 3.3\n",
    "all_I = np.array([min_power, max_power, min_power, max_power, min_power, max_power, min_power, max_power, min_power, max_power, \n",
    "                  min_power, max_power, min_power, max_power, min_power, max_power])\n",
    "energy = (durations/1000)*all_I\n",
    "total_energy = energy.sum()\n",
    "print(energy)\n",
    "print(total_energy)\n",
    "\n",
    "# ,current,duration_ms,Power,Energy\n",
    "# 257,0.04145261154220553,398.999989999993,0.13679361808927826,0.054580652249684884\n",
    "# 258,0.009509155411353975,365.4999900000462,0.031380212857468115,0.011469467485603915\n",
    "# 259,0.04149676357252121,398.999989999993,0.13693931978931997,0.05463878722654451\n",
    "# 260,0.009552000774134789,365.49998999998934,0.031521602554644805,0.011521145418506315\n",
    "# 261,0.041504126922542066,398.999989999993,0.13696361884438882,0.054648482549273986\n",
    "# 262,0.009516518708257437,365.49998999998934,0.03140451173724954,0.011478348725919256\n",
    "# 263,0.041612670504797666,398.9999900000498,0.1373218126658323,0.0547914018804558\n",
    "# 264,0.009498447700364296,365.49998999998934,0.03134487741120218,0.011456552380345288\n",
    "# 265,0.04139971011530399,105.14999999998054,0.13661904338050315,0.014365492411457247\n",
    "# 266,0.009560028642987248,365.49998999998934,0.03154809452185792,0.011530828232257788\n",
    "# 267,0.04172673550271172,398.999989999993,0.13769822715894867,0.05494159125943728\n",
    "# 268,0.009522545491803277,365.49998999998934,0.031424400122950814,0.011485617930694187\n",
    "# 269,0.04175801137533028,398.999989999993,0.13780143753858992,0.054982772199882034\n",
    "# 270,0.009517296286149161,364.499990000013,0.03140707774429223,0.011447879523724148\n",
    "# 271,0.041645176007866276,112.50000000001137,0.1374290808259587,0.015460771592921915\n",
    "# 272,0.009486789998786995,457.4999899999739,0.03130640699599708,0.014322680887603776\n",
    "# 273,0.04154616967213115,29.999989999964782,0.1371023599180328,0.004113069426512557"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
